\section{Metodologia para o treinamento dos modelos neurais}
\label{sec:TrainDeepModel}

Redes neurais profundas são modelos computacionais complexos, com vários parâmetros a serem configurados e decisões a serem tomadas tanto na arquitetura quanto nos otimizadores e métricas utilizadas durante o treino. Além disso, ao contrário de modelos computacionais convencionais, problemas presentes na codificação de redes neurais na maioria das vezes causam falhas silenciosas, o que dificulta a sua detecção e correção. Para minimizar os problemas citados acima, aqui será seguida a metodologia apresentada por \citeonline{KarpathyRecipe:2019}.  Tal metodologia divide o treinamento de uma rede neural em seis etapas distintas, cada uma servindo a um propósito específico.
\begin{itemize}
\item 
\textbf{Primeira etapa}, efetuar uma inspeção do conjunto de dados usado para treinamento e validação, visualizando os dados e entendendo a sua distribuição. 
O principal objetivo desta etapa é encontrar problemas que possam existir, como dados duplicados, corrompidos, ou então tendências que existam meio aos dados e que possam prejudicar o treinamento. Além disso, esta etapa serve para construir uma intuição sobre quais técnicas podem funcionar ou não com os dados.
\item 
\textbf{Segunda etapa}, construir um modelo \textit{baseline}, para que seja possível testar um código inicial para realizar as etapas de treino e avaliação. 
Nessa etapa, o foco não é obter os melhores resultados, mas sim em garantir que os dados estão sendo lidos e transformados de maneira correta, assim como o bom funcionamento de outros componentes vitais para o sistema como métricas e funções de perda. O código deve ser o mais simples possível, para que existam o mínimo de fatores que possam introduzir falhas.
\item 
\textbf{Terceira etapa}, modificar o  modelo \textit{baseline} até chegar em um modelo sobre ajustado ao conjunto de dados, ou seja, ele apresenta melhores resultados nos dados de treino que em nos dados de validação. 
A impossibilidade de alcançar o sobre-ajuste com modelos mais complexos é um indício de problemas que existem durante o treinamento.
\item 
\textbf{Quarta etapa}, regularizar o modelo sobre ajustado para que generalize nas predições e assim ganhar desempenho nos dados de validação em troca de uma perda de acurácia nos dados de treino. 
Para isso, serão utilizadas técnicas conhecidas na literatura por reduzir o sobre-ajuste dos modelos.
\item 
\textbf{Quinta etapa}, efetuar a sintonia dos hiper-parâmetros de treino para obter o melhor resultado possível, 
Como existem diferentes hiper-parâmetros, com os mais diversos efeitos sobre o treino, 
é recomendado utilizar uma política de busca aleatória para se encontrar os melhores valores \cite{BergstraAndBengio:2012}.
\item 
\textbf{Sexta etapa}, utilizar \textit{ensembles} de modelos ou treinar por mais tempo como último recurso para melhorar o desempenho do sistema como um todo.
\end{itemize}